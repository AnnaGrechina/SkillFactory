{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Прогнозирование стоимости автомобиля по характеристикам\n",
    "*Решение на основе шаблона (Baseline) к этому соревнованию*\n",
    "\n",
    "Основная работа проделана по сбору данных с сайта auto.ru\n",
    "Предобработка данных заключалась в максимально возможном переводе признаков в числовые\n",
    "(объем двигателя, мощность) и парсингу комплектации.\n",
    "Модель машинного обучения: стекинг CatBoost и RandomForest,\n",
    "в качестве метамодели - LinearRegression.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучающий датасет собран с помощью следующего кода:\n",
    "https://github.com/AnnaGrechina/SkillFactory/blob/master/RDS_3_CarPrice/auto_ru_Parcing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.notebook import tqdm\n",
    "from catboost import CatBoostRegressor\n",
    "import re\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python       : 3.7.7 (default, May  6 2020, 11:45:54) [MSC v.1916 64 bit (AMD64)]\n",
      "Numpy        : 1.18.1\n"
     ]
    }
   ],
   "source": [
    "print('Python       :', sys.version.split('\\n')[0])\n",
    "print('Numpy        :', np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# фиксируем RANDOM_SEED, чтобы эксперименты были воспроизводимы!\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION    = 5\n",
    "DIR_TRAIN  = '' # в отличие от Kaggle, данные в основной директории лежат\n",
    "DIR_TEST   = ''\n",
    "VAL_SIZE   = 0.1   \n",
    "N_FOLDS    = 5\n",
    "\n",
    "# CATBOOST\n",
    "ITERATIONS = 6000\n",
    "LR         = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DIR_TRAIN+'BMW_train.csv') # мой подготовленный датасет для обучения модели\n",
    "test = pd.read_csv(DIR_TEST+'test.csv')\n",
    "sample_submission = pd.read_csv(DIR_TEST+'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем записи с пропусками, заполняем малозначимые недостающие данные\n",
    "train = train.dropna(subset = ['price', 'name'])\n",
    "train['Владельцы'].fillna('3 или более', inplace = True)\n",
    "train['ПТС'].fillna('Оригинал', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_data(df_input):\n",
    "    '''includes several functions to pre-process the predictor data.'''\n",
    "    \n",
    "    df_output = df_input.copy()\n",
    "    \n",
    "    # ################### Предобработка ############################################################## \n",
    "    # убираем малозначащие для модели признаки,а также 'vehicleConfiguration' - информация дублируется в других признаках\n",
    "    df_output.drop(['id', 'Таможня', 'Состояние', 'vehicleConfiguration'], axis=1, inplace=True,)\n",
    "    \n",
    "    \n",
    "    # в явном виде переводим в числовые данные объем двигателя и мощность\n",
    "    df_output['enginePower'] = df_output['enginePower'].apply(lambda x: int(x[:-4]))\n",
    "    df_output['engineDisplacement'] = df_output['engineDisplacement'].apply(lambda x: \n",
    "                                                                            0 if x == 'undefined LTR' else 10 * float(x[:-4]))\n",
    "\n",
    "    # ################### fix ############################################################## \n",
    "    # Переводим признаки из float в int (иначе catboost выдает ошибку)\n",
    "    for feature in ['modelDate', 'numberOfDoors', 'mileage', 'productionDate', 'enginePower', 'engineDisplacement']:\n",
    "        df_output[feature]=df_output[feature].astype('int32')\n",
    "    \n",
    "\n",
    "    \n",
    "    # ################### Feature Engineering ####################################################\n",
    "    # Добавим признак = количеству опций\n",
    "    df_output['lenConfiguration'] = df_input['Комплектация'].apply(lambda x: len(configuration_parsing(x)))\n",
    "    \n",
    "    # ################### Clean #################################################### \n",
    "    # убираем признаки оставшиеся необработанные признаки и исходную комлектацию \n",
    "    df_output.drop(['description', 'Владение', 'Комплектация'], axis=1, inplace=True,)\n",
    "    \n",
    "    \n",
    "    return df_output\n",
    "\n",
    "###################################################\n",
    "\n",
    "# парсинг конфигурации автомобиля\n",
    "def configuration_parsing(txt):\n",
    "    configuration = []\n",
    "    pattern = r'\\\"values\\\":\\[(.+?)\\]}'\n",
    "    for txt_elem in re.findall(pattern, txt):\n",
    "        pattern_txt_elem = r'\\\"(.+?)\\\"'\n",
    "        for config_item in re.findall(pattern_txt_elem, txt_elem):\n",
    "            configuration.append(config_item)\n",
    "    return configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# код для one-hot-encoding данных комплектации\n",
    "set_configuration = set()\n",
    "for i in range(train.shape[0]):\n",
    "    txt = train['Комплектация'].iloc[i]\n",
    "    lst = configuration_parsing(txt)\n",
    "    set_configuration.update(set(lst))\n",
    "\n",
    "for i in range(test.shape[0]):\n",
    "    txt = test['Комплектация'].iloc[i]\n",
    "    lst = configuration_parsing(txt)\n",
    "    set_configuration.update(set(lst))\n",
    "    \n",
    "train = train.reindex(columns = train.columns.tolist() + list(set_configuration))\n",
    "test = test.reindex(columns = test.columns.tolist() + list(set_configuration))\n",
    "\n",
    "for col in set_configuration:\n",
    "    train[col] = train['Комплектация'].apply(lambda x: 1 if col in configuration_parsing(x) else 0)\n",
    "    test[col] = test['Комплектация'].apply(lambda x: 1 if col in configuration_parsing(x) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preproc = preproc_data(train)\n",
    "X_sub = preproc_data(test)\n",
    "\n",
    "train_preproc.drop(['URL'], axis=1, inplace=True,) # лишний столбец, которого нет в testе\n",
    "\n",
    "X = train_preproc.drop(['price'], axis=1,)\n",
    "# на основе экспериментов, введем коэффициент, учитывающий изменение экономической ситуации с момента собрания тестового датасета \n",
    "# и момента формирования тренировочного датасета\n",
    "\n",
    "y = 0.95 * train_preproc.price.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отметим категориальные признаки\n",
    "cat_features_ids = ['bodyType', 'brand', 'color', 'fuelType', 'name',\n",
    "         'vehicleTransmission', 'Привод', 'Руль', 'Владельцы', 'ПТС']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_meta_feature(model, X_train, X_test, y_train, cv):\n",
    "    \"\"\"\n",
    "    Computes meta-features usinf the classifier cls\n",
    "    \n",
    "    :arg model: scikit-learn classifier\n",
    "    :arg X_train, y_train: training set\n",
    "    :arg X_test: testing set\n",
    "    :arg cv: cross-validation folding\n",
    "    \"\"\"\n",
    "    \n",
    "    X_meta_train = np.zeros_like(y_train, dtype = np.float32)\n",
    "    for train_fold_index, predict_fold_index in cv.split(X_train):\n",
    "        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\n",
    "        y_fold_train = y_train[train_fold_index]\n",
    "        y_fold_test = y_train[predict_fold_index]\n",
    "        \n",
    "        folded_model = clone(model)\n",
    "        folded_model.fit(X_fold_train, y_fold_train)\n",
    "        X_meta_train[predict_fold_index] = folded_model.predict(X_fold_predict)\n",
    "        \n",
    "    meta_model = clone(model)\n",
    "    meta_model.fit(X_train, y_train)\n",
    "    \n",
    "    X_meta_test = meta_model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    return X_meta_train, X_meta_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.1877656\ttest: 1.1983567\tbest: 1.1983567 (0)\ttotal: 309ms\tremaining: 30m 51s\n",
      "1000:\tlearn: 0.1326998\ttest: 0.1433307\tbest: 0.1433307 (1000)\ttotal: 58.1s\tremaining: 4m 50s\n",
      "2000:\tlearn: 0.1212541\ttest: 0.1405281\tbest: 0.1405120 (1999)\ttotal: 1m 51s\tremaining: 3m 43s\n",
      "3000:\tlearn: 0.1134092\ttest: 0.1391019\tbest: 0.1390077 (2950)\ttotal: 2m 44s\tremaining: 2m 44s\n",
      "4000:\tlearn: 0.1071498\ttest: 0.1386272\tbest: 0.1386193 (3991)\ttotal: 3m 37s\tremaining: 1m 48s\n",
      "5000:\tlearn: 0.1014630\ttest: 0.1385299\tbest: 0.1382949 (4913)\ttotal: 4m 31s\tremaining: 54.2s\n",
      "5999:\tlearn: 0.0968663\ttest: 0.1386416\tbest: 0.1382949 (4913)\ttotal: 5m 25s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1382949028\n",
      "bestIteration = 4913\n",
      "\n",
      "Shrink model to first 4914 iterations.\n",
      "0:\tlearn: 1.2024224\ttest: 1.1086331\tbest: 1.1086331 (0)\ttotal: 66.2ms\tremaining: 6m 37s\n",
      "1000:\tlearn: 0.1315436\ttest: 0.1339522\tbest: 0.1339343 (999)\ttotal: 57.6s\tremaining: 4m 47s\n",
      "2000:\tlearn: 0.1201408\ttest: 0.1307653\tbest: 0.1307201 (1962)\ttotal: 1m 56s\tremaining: 3m 52s\n",
      "3000:\tlearn: 0.1131541\ttest: 0.1302701\tbest: 0.1302278 (2981)\ttotal: 2m 54s\tremaining: 2m 54s\n",
      "4000:\tlearn: 0.1070042\ttest: 0.1307540\tbest: 0.1302160 (3085)\ttotal: 3m 54s\tremaining: 1m 57s\n",
      "5000:\tlearn: 0.1016311\ttest: 0.1311233\tbest: 0.1302160 (3085)\ttotal: 4m 53s\tremaining: 58.7s\n",
      "5999:\tlearn: 0.0970344\ttest: 0.1313031\tbest: 0.1302160 (3085)\ttotal: 5m 52s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.130216022\n",
      "bestIteration = 3085\n",
      "\n",
      "Shrink model to first 3086 iterations.\n",
      "0:\tlearn: 1.1924798\ttest: 1.1560048\tbest: 1.1560048 (0)\ttotal: 54.9ms\tremaining: 5m 29s\n",
      "1000:\tlearn: 0.1314257\ttest: 0.1450051\tbest: 0.1449649 (983)\ttotal: 53.5s\tremaining: 4m 27s\n",
      "2000:\tlearn: 0.1188262\ttest: 0.1426482\tbest: 0.1425338 (1805)\ttotal: 1m 47s\tremaining: 3m 34s\n",
      "3000:\tlearn: 0.1116366\ttest: 0.1428026\tbest: 0.1425338 (1805)\ttotal: 2m 43s\tremaining: 2m 43s\n",
      "4000:\tlearn: 0.1055098\ttest: 0.1426104\tbest: 0.1425338 (1805)\ttotal: 3m 41s\tremaining: 1m 50s\n",
      "5000:\tlearn: 0.1001166\ttest: 0.1428245\tbest: 0.1425338 (1805)\ttotal: 4m 35s\tremaining: 55s\n",
      "5999:\tlearn: 0.0955500\ttest: 0.1427826\tbest: 0.1425338 (1805)\ttotal: 5m 30s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1425337931\n",
      "bestIteration = 1805\n",
      "\n",
      "Shrink model to first 1806 iterations.\n",
      "0:\tlearn: 1.1791014\ttest: 1.2472389\tbest: 1.2472389 (0)\ttotal: 86.5ms\tremaining: 8m 39s\n",
      "1000:\tlearn: 0.1309718\ttest: 0.1434791\tbest: 0.1434775 (999)\ttotal: 53.2s\tremaining: 4m 25s\n",
      "2000:\tlearn: 0.1191577\ttest: 0.1416821\tbest: 0.1416177 (1895)\ttotal: 1m 47s\tremaining: 3m 34s\n",
      "3000:\tlearn: 0.1112317\ttest: 0.1412039\tbest: 0.1410960 (2985)\ttotal: 2m 41s\tremaining: 2m 41s\n",
      "4000:\tlearn: 0.1048318\ttest: 0.1407750\tbest: 0.1407171 (3948)\ttotal: 3m 36s\tremaining: 1m 48s\n",
      "5000:\tlearn: 0.0992220\ttest: 0.1412275\tbest: 0.1406498 (4228)\ttotal: 4m 30s\tremaining: 54.1s\n",
      "5999:\tlearn: 0.0946826\ttest: 0.1414353\tbest: 0.1406498 (4228)\ttotal: 5m 24s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1406498297\n",
      "bestIteration = 4228\n",
      "\n",
      "Shrink model to first 4229 iterations.\n",
      "0:\tlearn: 1.1974994\ttest: 1.2513692\tbest: 1.2513692 (0)\ttotal: 55.4ms\tremaining: 5m 32s\n",
      "1000:\tlearn: 0.1322683\ttest: 0.1459194\tbest: 0.1458275 (988)\ttotal: 53.4s\tremaining: 4m 26s\n",
      "2000:\tlearn: 0.1210066\ttest: 0.1423475\tbest: 0.1423392 (1988)\ttotal: 1m 47s\tremaining: 3m 35s\n",
      "3000:\tlearn: 0.1132093\ttest: 0.1408927\tbest: 0.1408698 (2968)\ttotal: 2m 42s\tremaining: 2m 42s\n",
      "4000:\tlearn: 0.1065287\ttest: 0.1407490\tbest: 0.1405989 (3344)\ttotal: 3m 36s\tremaining: 1m 48s\n",
      "5000:\tlearn: 0.1009526\ttest: 0.1406439\tbest: 0.1404202 (4651)\ttotal: 4m 31s\tremaining: 54.3s\n",
      "5999:\tlearn: 0.0965136\ttest: 0.1406599\tbest: 0.1404202 (4651)\ttotal: 5m 25s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.140420181\n",
      "bestIteration = 4651\n",
      "\n",
      "Shrink model to first 4652 iterations.\n"
     ]
    }
   ],
   "source": [
    "n_foldes = 5\n",
    "cv = KFold(n_splits=n_foldes, shuffle=True)\n",
    "\n",
    "\n",
    "X_meta_train_features = []\n",
    "X_meta_test_features = []\n",
    "\n",
    "# 1 - catboost\n",
    "\n",
    "model = CatBoostRegressor(iterations = ITERATIONS,\n",
    "                          learning_rate = LR,\n",
    "                          random_seed = RANDOM_SEED,\n",
    "                          eval_metric='MAPE',\n",
    "                          custom_metric=['R2', 'MAE']\n",
    "                         )\n",
    "\n",
    "X_meta_train = np.zeros_like(y, dtype = np.float32)\n",
    "X_meta_test = np.zeros(len(X_sub), dtype = np.float32)\n",
    "for train_fold_index, predict_fold_index in cv.split(X):\n",
    "    X_fold_train, X_fold_predict = X.iloc[train_fold_index], X.iloc[predict_fold_index]\n",
    "    y_fold_train = y[train_fold_index]\n",
    "    y_fold_test = y[predict_fold_index]\n",
    "\n",
    "    folded_model = clone(model)\n",
    "    folded_model.fit(X_fold_train, y_fold_train,\n",
    "                     cat_features=cat_features_ids,\n",
    "                     eval_set=(X_fold_predict, y_fold_test),\n",
    "                     verbose_eval=1000,\n",
    "                     use_best_model=True,\n",
    "                     plot=False\n",
    ")\n",
    "    X_meta_train[predict_fold_index] = folded_model.predict(X_fold_predict)\n",
    "    X_meta_test += folded_model.predict(X_sub)\n",
    "    \n",
    "\n",
    "X_meta_test = X_meta_test / n_foldes\n",
    "\n",
    "X_meta_train_features.append(X_meta_train)\n",
    "X_meta_test_features.append(X_meta_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - randomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=300, random_state=42)\n",
    "\n",
    "X_meta_train = np.zeros_like(y, dtype = np.float32)\n",
    "X_train_num = X.drop(cat_features_ids, axis = 1)\n",
    "X_sub_num = X_sub.drop(cat_features_ids, axis = 1)\n",
    "\n",
    "for train_fold_index, predict_fold_index in cv.split(X_train_num):\n",
    "    X_fold_train, X_fold_predict = X_train_num.iloc[train_fold_index], X_train_num.iloc[predict_fold_index]\n",
    "    y_fold_train = y[train_fold_index]\n",
    "\n",
    "    folded_model = clone(model)\n",
    "    folded_model.fit(X_fold_train, y_fold_train)\n",
    "    X_meta_train[predict_fold_index] = folded_model.predict(X_fold_predict)\n",
    "\n",
    "meta_model = clone(model)\n",
    "meta_model.fit(X_train_num, y)\n",
    "\n",
    "X_meta_test = meta_model.predict(X_sub_num)\n",
    "\n",
    "X_meta_train_features.append(X_meta_train)\n",
    "X_meta_test_features.append(X_meta_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_features_train = np.vstack(X_meta_train_features).T\n",
    "stacked_features_test = np.vstack(X_meta_test_features).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1621740.        , 1620281.99366667],\n",
       "       [2485411.        , 2834278.53972222],\n",
       "       [1323980.25      , 1346865.66666667],\n",
       "       [2427400.75      , 2437585.99683333],\n",
       "       [5008473.        , 4769796.76183333],\n",
       "       [2023370.375     , 2116220.703     ],\n",
       "       [1090368.875     , 1006932.93633333],\n",
       "       [ 680486.1875    ,  707463.41666667],\n",
       "       [1444184.875     , 1481695.47222222],\n",
       "       [1398908.25      , 1331333.16666667]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_features_test[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1620000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2530000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1320000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2430000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2030000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1080000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>680000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1450000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1390000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      price\n",
       "0   0  1620000.0\n",
       "1   1  2530000.0\n",
       "2   2  1320000.0\n",
       "3   3  2430000.0\n",
       "4   4  5000000.0\n",
       "5   5  2030000.0\n",
       "6   6  1080000.0\n",
       "7   7   680000.0\n",
       "8   8  1450000.0\n",
       "9   9  1390000.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = LinearRegression()\n",
    "final_model.fit(stacked_features_train, y)\n",
    "sample_submission['price'] = np.floor(final_model.predict(stacked_features_test) / 10000) * 10000 \n",
    "sample_submission.to_csv(f'submission_stack_v{VERSION}_BMW.csv', index=False)\n",
    "sample_submission.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
